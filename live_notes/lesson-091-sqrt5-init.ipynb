{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 9 \n",
    "\n",
    "#### How to Train your model\n",
    "\n",
    "<img src=\"https://snag.gy/GxVakf.jpg\" width=\"600px\"/>\n",
    "\n",
    "#### Recap from last Lesson\n",
    "\n",
    "- We looked at Conv2D, and looked at how it initializes parameters\n",
    "- We found `math.sqrt(5)` and didn't know the reasoning\n",
    "- How I researched: [fastai nb link](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/02a_why_sqrt5.ipynb)\n",
    "- Step 1: loaded everything we had from last week\n",
    "- Step 2: used MNIST\n",
    "- Step 3: setup a Conv2D layer\n",
    "- Step 4: looked at the first 100 samples\n",
    "- Step 5: look at the mean / std of different weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_lib import *\n",
    "\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, m, s): \n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why SQRT(5)?\n",
    "\n",
    "`torch.nn.modules.conv._ConvNd.reset_parameters??`\n",
    "\n",
    "    Signature: torch.nn.modules.conv._ConvNd.reset_parameters(self)\n",
    "    Docstring: <no docstring>\n",
    "    Source:   \n",
    "        def reset_parameters(self):\n",
    "            n = self.in_channels\n",
    "            init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "            if self.bias is not None:\n",
    "                fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                init.uniform_(self.bias, -bound, bound)\n",
    "    File:      ~/envs/py3/lib/python3.6/site-packages/torch/nn/modules/conv.py\n",
    "    Type:      function\n",
    "    \n",
    "    \n",
    "To test out and understand the reasoning behind the square root 5, we will start with MNIST data and observe how the initialization affects the performance. The following code block will load and prepare the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, tensor(10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load our data from MNIST\n",
    "x_train, y_train, x_valid, y_valid = get_data()\n",
    "\n",
    "# find our mean and std\n",
    "train_mean, train_std = x_train.mean(), x_train.std()\n",
    "\n",
    "# normalize the training and the validation data\n",
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid, train_mean, train_std)\n",
    "\n",
    "# because the data comes in single vectors, we\n",
    "# will reshape to the 28 x 28 sized 1 channel format images\n",
    "x_train = x_train.view(-1,1,28,28)\n",
    "x_valid = x_valid.view(-1,1,28,28)\n",
    "x_train.shape, x_valid.shape\n",
    "\n",
    "# get the number of samples\n",
    "n, *_ = x_train.shape\n",
    "\n",
    "# number of classes\n",
    "c = y_train.max()+1\n",
    "\n",
    "# number of hidden units\n",
    "nh = 32\n",
    "n, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's experiment with the Conv2d\n",
    "\n",
    "We will make a single conv2d layer, with 1 channel, and a 5x5 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "l1 = nn.Conv2d(1, nh, 5)\n",
    "\n",
    "# look at the first 100 examples for testing\n",
    "x = x_valid[:100]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the weights, we have\n",
    "- 32 different filters\n",
    "- 1 channel\n",
    "- 5 kernel width\n",
    "- 5 kernel height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 5, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the weights which are initialized with kaiming_normal and with sqrt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.0084, grad_fn=<MeanBackward1>), tensor(0.1142, grad_fn=<StdBackward0>)) (tensor(-0.0250, grad_fn=<MeanBackward1>), tensor(0.1251, grad_fn=<StdBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# we will be keeping track of the weights as the layer trains\n",
    "def stats(x): \n",
    "    \"\"\" Returns mean and std \"\"\"\n",
    "    return x.mean(), x.std()\n",
    "\n",
    "print(stats(l1.weight), stats(l1.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass the first 100 samples through the Conv2D\n",
    "\n",
    "if we look at the stats of result `t`, we see that the mean is close to zero, but the **standard deviation is NOT close to 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0039, grad_fn=<MeanBackward1>),\n",
       " tensor(0.5825, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]